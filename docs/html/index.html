<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Use Deep Learning in Data Assimilation &#8212; torchda  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=b3ba4146"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="use-deep-learning-in-data-assimilation">
<h1>Use Deep Learning in Data Assimilation<a class="headerlink" href="#use-deep-learning-in-data-assimilation" title="Permalink to this heading">¶</a></h1>
<section id="torchda">
<h2>torchda<a class="headerlink" href="#torchda" title="Permalink to this heading">¶</a></h2>
<p>Important Notes:</p>
<ul class="simple">
<li><p>Background state <cite>x0</cite> or <cite>xb</cite> must be a 1D or 2D tensor with shape
([<cite>batch size</cite>], state dimension), and <cite>batch size</cite> is optional.
<cite>batch size</cite> is only available for 3D Variational (3D-Var) algorithm.</p></li>
<li><p>Observations or measurements <cite>y</cite> must be a 2D tensor.</p>
<ul>
<li><p>The shape of <cite>y</cite> must be (number of observations, state dimension) for Kalman Filter (KF),
Ensemble Kalman Filter (EnKF), and 4D Variational (4D-Var) algorithm. The number of
observations must be at least 1 in KF or EnKF, and this number must be at least 2 in 4D-Var.</p></li>
<li><p>The shape of <cite>y</cite> must be ([<cite>batch size</cite>], state dimension) for 3D-Var algorithm, and
<cite>batch size</cite> is optional for <code class="docutils literal notranslate"><span class="pre">batch</span> <span class="pre">size</span> <span class="pre">==</span> <span class="pre">1</span></code>.</p></li>
</ul>
</li>
<li><p>A callable code object <cite>M</cite> must be able to handle the 1D tensor input <cite>x</cite> with shape (state dimension,).
The output of the <cite>M</cite> must be a 2D tensor with shape (time window sequence length, state dimension).</p></li>
<li><p><cite>H</cite> could be either a tensor or a callable code object, and tensor <cite>H</cite> is only available in KF algorithm.</p>
<ul>
<li><p>If <cite>H</cite> is a callable code object, it must be able to handle the input <cite>x</cite> in 2D tensor with
shape ([<cite>number of ensemble</cite>], state dimension), and default <code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">ensemble</span> <span class="pre">==</span> <span class="pre">1</span></code>
for all algorithms except EnKF. The output of this callable code object <cite>H</cite> must
be a corresponding shape ([<cite>number of ensemble</cite>], measurement dimension), and the output must be a
2D tensor with shape (1, state dimension) in all other algorithms.</p></li>
<li><p>If <cite>H</cite> is a tensor, it must be a 2D tensor of shape (measurement dimension, state dimension).
This matrix maps the state space to the measurement space.</p></li>
<li><p>Notice: A callable <cite>H</cite> code object would be approximated by the Jacobian method in KF algorithm.
That might cause unexpected error due to incorrect shaping of tensor.
Recommended input tensor <cite>x</cite> for the callable <cite>H</cite> is a 1D tensor (state dimension,) in KF algorithm.</p></li>
</ul>
</li>
</ul>
<span class="target" id="module-torchda"></span><section id="id1">
<h3>TorchDA<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>Use Deep Learning in Data Assimilation</p>
<p>TorchDA is a Python package that provides a flexible and user-friendly
framework for performing data assimilation with neural networks on
various algorithms, including Ensemble Kalman Filter (EnKF),
3D Variational (3D-Var) assimilation, and
4D Variational (4D-Var) assimilation.</p>
<p>This package is designed to simplify the process of configuring and
executing data assimilation cases, making it easier for researchers
and practitioners to apply data assimilation techniques with
neural networks to their scientific and engineering problems.</p>
<section id="modules">
<h4>Modules<a class="headerlink" href="#modules" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><dl class="simple">
<dt>parameters:</dt><dd><p>Contains the Parameters class for specifying data assimilation parameters.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>builder:</dt><dd><p>Provides a CaseBuilder class for configuring and
executing data assimilation cases.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>executor:</dt><dd><p>Implements the _Executor class for executing data assimilation cases.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>kalman_filter:</dt><dd><p>Implements EnKF and Kalman Filter algorithms for data assimilation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>variational:</dt><dd><p>Implements 3D-Var and 4D-Var algorithms for variational data assimilation.</p>
</dd>
</dl>
</li>
</ul>
<p>For more information, please refer to the package documentation.</p>
</section>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="torchda.CaseBuilder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">CaseBuilder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">case_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torchda.Parameters" title="torchda.parameters.Parameters"><span class="pre">Parameters</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchda.CaseBuilder" title="Permalink to this definition">¶</a></dt>
<dd><p>A builder class for configuring and executing
data assimilation cases.</p>
<p>This class provides a convenient way for users to set up
and execute data assimilation cases using various algorithms,
including Ensemble Kalman Filter (EnKF), 3D-Var, and 4D-Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>case_name</strong> (<em>str</em><em>, </em><em>optional</em>) – A name for the data assimilation case.
Default is ‘case_{current_timestamp}’.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><a class="reference internal" href="#torchda.Parameters" title="torchda.Parameters"><em>Parameters</em></a><em>, </em><em>optional</em>) – A dictionary or an instance of Parameters class containing
configuration parameters for the data assimilation case.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.CaseBuilder.case_name">
<span class="sig-name descname"><span class="pre">case_name</span></span><a class="headerlink" href="#torchda.CaseBuilder.case_name" title="Permalink to this definition">¶</a></dt>
<dd><p>A name for the data assimilation case.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torchda.Parameters" title="torchda.Parameters"><span class="pre">Parameters</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchda.CaseBuilder.set_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>-&gt; CaseBuilder:
Set a batch of parameters for the data assimilation case.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_parameter">
<span class="sig-name descname"><span class="pre">set_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Set a parameter for the data assimilation case.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_algorithm">
<span class="sig-name descname"><span class="pre">set_algorithm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Algorithms</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the data assimilation algorithm to use (EnKF, 3D-Var, 4D-Var).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_device">
<span class="sig-name descname"><span class="pre">set_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Device</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the device (CPU or GPU) for computations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_forward_model(forward_model:</span> <span class="pre">Callable[[torch.Tensor,</span> <span class="pre">_GenericTensor],</span></span></dt>
<dd><p>torch.Tensor] | Callable[…, torch.Tensor]) -&gt; CaseBuilder:
Set the state transition function ‘M’ for EnKF.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_output_sequence_length">
<span class="sig-name descname"><span class="pre">set_output_sequence_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">&quot;CaseBuilder&quot;:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_output_sequence_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the output sequence length for the forward model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_observation_model(observation_model:</span> <span class="pre">torch.Tensor</span> <span class="pre">|</span></span></dt>
<dd><p>Callable[[torch.Tensor], torch.Tensor]) -&gt; CaseBuilder:
Set the observation model or matrix ‘H’ for EnKF.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_background_covariance_matrix">
<span class="sig-name descname"><span class="pre">set_background_covariance_matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchda.CaseBuilder.set_background_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>(background_covariance_matrix: torch.Tensor) -&gt; CaseBuilder:
Set the background covariance matrix ‘B’.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_observation_covariance_matrix">
<span class="sig-name descname"><span class="pre">set_observation_covariance_matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchda.CaseBuilder.set_observation_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>(observation_covariance_matrix: torch.Tensor) -&gt; CaseBuilder:
Set the observation covariance matrix ‘R’.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_background_state">
<span class="sig-name descname"><span class="pre">set_background_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">background_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_background_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial background state estimate ‘xb’.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_observations">
<span class="sig-name descname"><span class="pre">set_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the observed measurements.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_observation_time_steps">
<span class="sig-name descname"><span class="pre">set_observation_time_steps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_time_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchda.CaseBuilder.set_observation_time_steps" title="Permalink to this definition">¶</a></dt>
<dd><p>-&gt; CaseBuilder:
Set the observation time steps.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_gaps">
<span class="sig-name descname"><span class="pre">set_gaps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gaps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_gaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the number sequence of time steps between observations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_num_ensembles">
<span class="sig-name descname"><span class="pre">set_num_ensembles</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_ensembles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_num_ensembles" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the number of ensembles for EnKF.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_start_time">
<span class="sig-name descname"><span class="pre">set_start_time</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_start_time" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the starting time of the data assimilation process.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_args">
<span class="sig-name descname"><span class="pre">set_args</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Set additional arguments for state transition function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_max_iterations">
<span class="sig-name descname"><span class="pre">set_max_iterations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_max_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the maximum number of iterations for
optimization-based algorithms.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_learning_rate">
<span class="sig-name descname"><span class="pre">set_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_learning_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the learning rate for optimization-based algorithms.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.set_record_log">
<span class="sig-name descname"><span class="pre">set_record_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">record_log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">CaseBuilder:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.set_record_log" title="Permalink to this definition">¶</a></dt>
<dd><p>Set whether to record and print log messages during execution.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.execute">
<span class="sig-name descname"><span class="pre">execute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict[str,</span> <span class="pre">torch.Tensor</span> <span class="pre">|</span> <span class="pre">dict[str,</span> <span class="pre">list]]:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.execute" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the data assimilation case and return the results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.get_results_dict">
<span class="sig-name descname"><span class="pre">get_results_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict[str,</span> <span class="pre">torch.Tensor</span> <span class="pre">|</span> <span class="pre">dict[str,</span> <span class="pre">list]]:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.get_results_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the dictionary containing the results of the executed case.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.get_parameters_dict">
<span class="sig-name descname"><span class="pre">get_parameters_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict[str,</span> <span class="pre">Any]:</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.get_parameters_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the dictionary of configured parameters for the case.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.check_covariance_matrix">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">check_covariance_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cov_matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchda.CaseBuilder.check_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a given covariance matrix is valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>cov_matrix</strong> (<em>torch.Tensor</em>) – The covariance matrix to be checked.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>LinAlgError</strong> – If the covariance matrix is not a valid square matrix,
    not symmetric, or is singular.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda.CaseBuilder.get_result">
<span class="sig-name descname"><span class="pre">get_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda.CaseBuilder.get_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a specific result from the executed case by name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – <p>The name of the result to retrieve.</p>
<ul class="simple">
<li><dl class="simple">
<dt>’average_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’each_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’assimilated_state’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’intermediate_results’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A requested result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor | dict[str, list]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchda.Parameters">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">Parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">algorithm:</span> <span class="pre">~torchda.Algorithms</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">device:</span> <span class="pre">~torchda.Device</span> <span class="pre">=</span> <span class="pre">Device.CPU,</span> <span class="pre">observation_model:</span> <span class="pre">~torch.Tensor</span> <span class="pre">|</span> <span class="pre">~typing.Callable[[~torch.Tensor],</span> <span class="pre">~torch.Tensor]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">background_covariance_matrix:</span> <span class="pre">~torch.Tensor</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">observation_covariance_matrix:</span> <span class="pre">~torch.Tensor</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">background_state:</span> <span class="pre">~torch.Tensor</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">observations:</span> <span class="pre">~torch.Tensor</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">forward_model:</span> <span class="pre">~typing.Callable[[~torch.Tensor,</span> <span class="pre">~torchda._GenericTensor],</span> <span class="pre">~torch.Tensor]</span> <span class="pre">|</span> <span class="pre">~typing.Callable[[...],</span> <span class="pre">~torch.Tensor]</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">Parameters.&lt;lambda&gt;&gt;,</span> <span class="pre">output_sequence_length:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">observation_time_steps:</span> <span class="pre">~torchda._GenericTensor</span> <span class="pre">=</span> <span class="pre">(),</span> <span class="pre">gaps:</span> <span class="pre">~torchda._GenericTensor</span> <span class="pre">=</span> <span class="pre">(),</span> <span class="pre">num_ensembles:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0,</span> <span class="pre">start_time:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.0,</span> <span class="pre">max_iterations:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">1000,</span> <span class="pre">learning_rate:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.001,</span> <span class="pre">record_log:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">args:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">()</span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchda.Parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Data class to hold parameters for data assimilation.</p>
<p>This class encapsulates the parameters required for data assimilation
algorithms, such as Ensemble Kalman Filter (EnKF), 3D-Var, and 4D-Var.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.algorithm">
<span class="sig-name descname"><span class="pre">algorithm</span></span><a class="headerlink" href="#torchda.Parameters.algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>The data assimilation algorithm to use (EnKF, 3D-Var, 4D-Var).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Algorithms</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#torchda.Parameters.device" title="Permalink to this definition">¶</a></dt>
<dd><p>The device (CPU or GPU) to perform computations on. Default is CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Device, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.observation_model">
<span class="sig-name descname"><span class="pre">observation_model</span></span><a class="headerlink" href="#torchda.Parameters.observation_model" title="Permalink to this definition">¶</a></dt>
<dd><p>The observation model or matrix ‘H’ that relates the state space to
the observation space. It can be a pre-defined tensor or a Callable
function that computes observations from the state.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor | Callable[[torch.Tensor], torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.background_covariance_matrix">
<span class="sig-name descname"><span class="pre">background_covariance_matrix</span></span><a class="headerlink" href="#torchda.Parameters.background_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>The background covariance matrix ‘B’ representing the uncertainty
of the background state estimate.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.observation_covariance_matrix">
<span class="sig-name descname"><span class="pre">observation_covariance_matrix</span></span><a class="headerlink" href="#torchda.Parameters.observation_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>The observation covariance matrix ‘R’ representing the uncertainty
in the measurements.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.background_state">
<span class="sig-name descname"><span class="pre">background_state</span></span><a class="headerlink" href="#torchda.Parameters.background_state" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial background state estimate ‘xb’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.observations">
<span class="sig-name descname"><span class="pre">observations</span></span><a class="headerlink" href="#torchda.Parameters.observations" title="Permalink to this definition">¶</a></dt>
<dd><p>The observed measurements corresponding to the given observation times.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.forward_model">
<span class="sig-name descname"><span class="pre">forward_model</span></span><a class="headerlink" href="#torchda.Parameters.forward_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Callable[…, torch.Tensor], optional
The state transition function ‘M’ that predicts the state of the
system given the previous state and the time range.
Required for EnKF and 4D-Var.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Callable[[torch.Tensor, _GenericTensor], torch.Tensor] |</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.output_sequence_length">
<span class="sig-name descname"><span class="pre">output_sequence_length</span></span><a class="headerlink" href="#torchda.Parameters.output_sequence_length" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of output states along the time for the forward model.
Used to determine the length of the output sequence
for the forward model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.observation_time_steps">
<span class="sig-name descname"><span class="pre">observation_time_steps</span></span><a class="headerlink" href="#torchda.Parameters.observation_time_steps" title="Permalink to this definition">¶</a></dt>
<dd><p>A 1D array containing the observation times in increasing order.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>_GenericTensor, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.gaps">
<span class="sig-name descname"><span class="pre">gaps</span></span><a class="headerlink" href="#torchda.Parameters.gaps" title="Permalink to this definition">¶</a></dt>
<dd><p>A 1D array containing the number of time steps
between consecutive observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>_GenericTensor, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.num_ensembles">
<span class="sig-name descname"><span class="pre">num_ensembles</span></span><a class="headerlink" href="#torchda.Parameters.num_ensembles" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of ensembles used in the
Ensemble Kalman Filter (EnKF) algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.start_time">
<span class="sig-name descname"><span class="pre">start_time</span></span><a class="headerlink" href="#torchda.Parameters.start_time" title="Permalink to this definition">¶</a></dt>
<dd><p>The starting time of the data assimilation process. Default is 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int | float, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.max_iterations">
<span class="sig-name descname"><span class="pre">max_iterations</span></span><a class="headerlink" href="#torchda.Parameters.max_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p>The maximum number of iterations for
optimization-based algorithms (3D-Var, 4D-Var).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.learning_rate">
<span class="sig-name descname"><span class="pre">learning_rate</span></span><a class="headerlink" href="#torchda.Parameters.learning_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The learning rate for optimization-based algorithms (3D-Var, 4D-Var).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int | float, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.record_log">
<span class="sig-name descname"><span class="pre">record_log</span></span><a class="headerlink" href="#torchda.Parameters.record_log" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether to record and print logs for iteration progress.
Default is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchda.Parameters.args">
<span class="sig-name descname"><span class="pre">args</span></span><a class="headerlink" href="#torchda.Parameters.args" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional arguments to pass to state transition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple, optional</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Ensure that the provided tensors are properly shaped and compatible with
the algorithm’s requirements.</p></li>
<li><p>For EnKF, ‘forward_model’ should be provided,
and ‘observation_time_steps’ should have at least 1 time point.</p></li>
<li><p>For 3D-Var and 4D-Var, ‘max_iterations’ and ‘learning_rate’ control the
optimization process.</p></li>
<li><p>For 4D-Var, ‘observation_time_steps’ should have at least 2 time points.</p></li>
</ul>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchda._Executor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">_Executor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchda.Parameters" title="torchda.parameters.Parameters"><span class="pre">Parameters</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchda._Executor" title="Permalink to this definition">¶</a></dt>
<dd><p>Data assimilation executor class.</p>
<p>This class provides a high-level integration for configuring and running
data assimilation algorithms. It supports Ensemble Kalman Filter (EnKF),
3D-Var, and 4D-Var.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There is no validation for input parameters in this class.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>parameters</strong> (<a class="reference internal" href="#torchda.Parameters" title="torchda.Parameters"><em>Parameters</em></a><em>, </em><em>optional</em>) – An instance of Parameters class containing
configuration parameters for the data assimilation case.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchda._Executor.get_result">
<span class="sig-name descname"><span class="pre">get_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda._Executor.get_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a deep copy of a specific result by name
from the results dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – <p>The name of the result to retrieve.</p>
<ul class="simple">
<li><dl class="simple">
<dt>’average_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’each_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’assimilated_state’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’intermediate_results’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A deep copy of the requested result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor | dict[str, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda._Executor.get_results_dict">
<span class="sig-name descname"><span class="pre">get_results_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda._Executor.get_results_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a deep copy of the results dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>A deep copy of the results dictionary containing
data assimilation results.</p>
<ul class="simple">
<li><dl class="simple">
<dt>’average_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’each_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’assimilated_state’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’intermediate_results’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, torch.Tensor | dict[str, list]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda._Executor.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda._Executor.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the selected data assimilation algorithm and return results.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>A dictionary containing the results of the
data assimilation algorithm.</p>
<ul class="simple">
<li><dl class="simple">
<dt>’average_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’each_ensemble_all_states’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.EnKF</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’assimilated_state’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’intermediate_results’</dt><dd><p>Only available when algorithm is <code class="docutils literal notranslate"><span class="pre">Algorithms.Var3D</span></code>
or <code class="docutils literal notranslate"><span class="pre">Algorithms.Var4D</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, torch.Tensor | dict[str, list]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchda._Executor.set_input_parameters">
<span class="sig-name descname"><span class="pre">set_input_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchda.Parameters" title="torchda.parameters.Parameters"><span class="pre">Parameters</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchda._Executor" title="torchda.executor._Executor"><span class="pre">_Executor</span></a></span></span><a class="headerlink" href="#torchda._Executor.set_input_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the input parameters for the data assimilation algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>parameters</strong> (<a class="reference internal" href="#torchda.Parameters" title="torchda.Parameters"><em>Parameters</em></a>) – An instance of the Parameters data class containing
the configuration for the data assimilation algorithm.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The _Executor instance with updated input parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchda._Executor" title="torchda._Executor">_Executor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchda.apply_3DVar">
<span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">apply_3DVar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">H</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda.apply_3DVar" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the 3D-Var (Three-Dimensional Variational) assimilation.</p>
<p>This function applies the 3D-Var assimilation algorithm to estimate
the state of a dynamic system given noisy measurements. It aims to find
the optimal state that minimizes the cost function combining background
error and observation error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>H</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em>) – The observation operator that maps the state space to the observation
space.
It should have the signature H(x: torch.Tensor) -&gt; torch.Tensor.</p></li>
<li><p><strong>B</strong> (<em>torch.Tensor</em>) – The background error covariance matrix.
A 2D tensor of shape (state_dim, state_dim).
It represents the uncertainty in the background.</p></li>
<li><p><strong>R</strong> (<em>torch.Tensor</em>) – The observation error covariance matrix.
A 2D tensor of shape (observation_dim, observation_dim).
It models the uncertainty in the measurements.</p></li>
<li><p><strong>xb</strong> (<em>torch.Tensor</em>) – The background state estimate. A 1D or 2D tensor of shape
(state_dim,) or (batch_size, state_dim).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – The observed measurements. A 1D or 2D tensor of shape
(observation_dim,) or (batch_size, observation_dim).</p></li>
<li><p><strong>max_iterations</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum number of optimization iterations. Default is 1000.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The learning rate for the optimization algorithm. Default is 1e-3.</p></li>
<li><p><strong>record_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to record and print logs for iteration progress.
Default is True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x_optimal</strong> (<em>torch.Tensor</em>) – The optimal state estimate obtained using the 3D-Var assimilation.</p></li>
<li><p><strong>intermediate_results</strong> (<em>dict[str, list]</em>) – A dictionary containing intermediate results during optimization.</p>
<ul>
<li><dl class="simple">
<dt>’J’</dt><dd><p>List of cost function values at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’J_grad_norm’</dt><dd><p>List of norms of the cost function gradients at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’background_states’</dt><dd><p>List of background state estimates at each iteration.</p>
</dd>
</dl>
</li>
</ul>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>TypeError</strong> – If ‘H’ is not a Callable.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The function assumes that the input tensors are properly shaped
and valid for the 3D-Var assimilation. Ensure that ‘xb’, ‘B’, ‘R’,
and ‘y’ are appropriate for the dimensions of ‘H’.</p></li>
<li><p>The 3D-Var algorithm seeks an optimal state estimate by
minimizing a cost function that incorporates both
background and observation errors.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchda.apply_4DVar">
<span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">apply_4DVar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_obs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_GenericTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda.apply_4DVar" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the 4D-Var (Four-Dimensional Variational) assimilation.</p>
<p>This function applies the 4D-Var assimilation algorithm to estimate
the state of a dynamic system given noisy measurements. It aims to find
the optimal state that minimizes the cost function combining background
error and observation error over a specified time window.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_obs</strong> (<em>_GenericTensor</em>) – A 1D array containing the observation times in increasing order.</p></li>
<li><p><strong>gaps</strong> (<em>_GenericTensor</em>) – A 1D array containing the number of time steps
between consecutive observations.</p></li>
<li><p><strong>M</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>, </em><em>_GenericTensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>] </em><em>|</em>) – Callable[…, torch.Tensor]
The state transition function (process model) that predicts the state
of the system given the previous state and the time range.
It should have the signature
M(x: torch.Tensor, time_range: torch.Tensor, *args) -&gt; torch.Tensor.
‘x’ is the state vector, ‘time_range’ is a 1D tensor of time steps to
predict the state forward, and ‘*args’ represents any additional
arguments required by the state transition function.</p></li>
<li><p><strong>H</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em>) – The observation operator that maps the state space to the observation
space.
It should have the signature H(x: torch.Tensor) -&gt; torch.Tensor.</p></li>
<li><p><strong>B</strong> (<em>torch.Tensor</em>) – The background error covariance matrix.
A 2D tensor of shape (state_dim, state_dim).
It represents the uncertainty in the background.</p></li>
<li><p><strong>R</strong> (<em>torch.Tensor</em>) – The observation error covariance matrix.
A 2D tensor of shape (observation_dim, observation_dim).
It models the uncertainty in the measurements.</p></li>
<li><p><strong>xb</strong> (<em>torch.Tensor</em>) – The background state estimate. A 1D tensor of shape (state_dim).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – The observed measurements. A 2D tensor of shape
(number of observations, measurement_dim).
Each row represents a measurement at a specific time step.</p></li>
<li><p><strong>args</strong> (<em>tuple</em><em>, </em><em>optional</em>) – Additional arguments to pass to the state transition function ‘M’.</p></li>
<li><p><strong>max_iterations</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum number of optimization iterations. Default is 1000.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The learning rate for the optimization algorithm. Default is 1e-3.</p></li>
<li><p><strong>record_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to record and print logs for iteration progress.
Default is True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x_optimal</strong> (<em>torch.Tensor</em>) – The optimal state estimate obtained using the 4D-Var assimilation.</p></li>
<li><p><strong>intermediate_results</strong> (<em>dict[str, list]</em>) – A dictionary containing intermediate results during optimization.</p>
<ul>
<li><dl class="simple">
<dt>’Jb’</dt><dd><p>List of background cost function values at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’Jo’</dt><dd><p>List of observation cost function values at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’J’</dt><dd><p>List of cost function values at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’J_grad_norm’</dt><dd><p>List of norms of the cost function gradients at each iteration.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’background_states’</dt><dd><p>List of background state estimates at each iteration.</p>
</dd>
</dl>
</li>
</ul>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>TypeError</strong> – If ‘M’ or ‘H’ are not Callable, or if ‘y’ is not a tuple or list.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The function assumes that the input tensors are properly shaped
and valid for the 4D-Var assimilation. Ensure that ‘xb’, ‘B’, ‘R’,
and ‘y’ are appropriate for the dimensions of ‘M’, ‘H’,
and the observation times.</p></li>
<li><p>The 4D-Var algorithm seeks an optimal state estimate over a time window
by minimizing a cost function that incorporates both background and
observation errors.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchda.apply_EnKF">
<span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">apply_EnKF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_obs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ne</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_GenericTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchda.apply_EnKF" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the Ensemble Kalman Filter
See e.g. Evensen, Ocean Dynamics (2003), Eqs. 44–54</p>
<p>This function applies the Ensemble Kalman Filter algorithm to estimate
the state of a dynamic system given noisy measurements.
It uses an ensemble of state estimates to represent
the uncertainty in the estimated state.
It is executed within a no-grad context, meaning that gradient computation
is disabled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_obs</strong> (<em>_GenericTensor</em>) – A 1D array containing the observation times in increasing order.</p></li>
<li><p><strong>gaps</strong> (<em>_GenericTensor</em>) – A 1D array containing the number of time steps
between consecutive observations.</p></li>
<li><p><strong>Ne</strong> (<em>int</em>) – The number of ensemble members representing the state estimates.</p></li>
<li><p><strong>M</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>, </em><em>_GenericTensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>] </em><em>|</em>) – Callable[…, torch.Tensor]
The state transition function (process model) that predicts the state
of the system given the previous state and the time range. It should
have the signature
M(x: torch.Tensor, time_range: torch.Tensor, *args) -&gt; torch.Tensor.
‘x’ is the state vector, ‘time_range’ is a 1D tensor of time steps to
predict the state forward, and ‘*args’ represents any additional
arguments required by the state transition function.</p></li>
<li><p><strong>H</strong> (<em>torch.Tensor</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em>) – The measurement matrix or a function that
computes the measurement matrix. If ‘H’ is a torch.Tensor,
it is a 2D tensor of shape (measurement_dim, state_dim),
where ‘measurement_dim’ is the dimension of measurement
and ‘state_dim’ is the dimension of the state vector.
This matrix maps the state space to the measurement space.
If ‘H’ is a Callable, it should have the signature
H(x: torch.Tensor) -&gt; torch.Tensor to compute the measurement,
and ‘H’ must be able to handle the input ‘x’ with shape
(number of ensemble, state_dim). The output of Callable ‘H’
must be a Tensor with shape (number of ensemble, measurement_dim).</p></li>
<li><p><strong>P0</strong> (<em>torch.Tensor</em>) – The initial covariance matrix of the state estimate. A 2D tensor of
shape (state_dim, state_dim). It represents the uncertainty of the
initial state estimate.</p></li>
<li><p><strong>R</strong> (<em>torch.Tensor</em>) – The measurement noise covariance matrix. A 2D tensor of shape
(measurement_dim, measurement_dim). It models the uncertainty in
the measurements.</p></li>
<li><p><strong>x0</strong> (<em>torch.Tensor</em>) – The initial state estimate. A 1D tensor of shape (state_dim).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – The observed measurements. A 2D tensor of shape
(number of observations, measurement_dim). Each row represents
a measurement at a specific time step.</p></li>
<li><p><strong>args</strong> (<em>tuple</em><em>, </em><em>optional</em>) – Additional arguments to pass to the state transition function ‘M’.</p></li>
<li><p><strong>start_time</strong> (<em>float</em><em>, </em><em>optional</em>) – The starting time of the filtering process. Default is 0.0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x_ave</strong> (<em>torch.Tensor</em>) – A 2D tensor of shape (num_steps + 1, state_dim). Each row represents
the ensemble mean state vector at a specific time step, including
the initial state.</p></li>
<li><p><strong>x_ens</strong> (<em>torch.Tensor</em>) – A 3D tensor of shape (num_steps + 1, Ne, state_dim). Each slice along
the second dimension represents an ensemble member’s state estimates
at a specific time step, including the initial state.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>TypeError</strong> – If ‘M’ is not a Callable or ‘H’ is not a torch.Tensor or Callable.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The function assumes that the input tensors are properly shaped
and valid for the Ensemble Kalman Filter. Ensure that ‘x0’, ‘P0’, ‘R’,
and ‘y’ are appropriate for the dimensions of ‘M’ and ‘H’.</p></li>
<li><p>The function assumes that ‘time_obs’ contains time points
that are increasing, and ‘gaps’ specifies each number of time steps
between consecutive observations.</p></li>
<li><p>The implementation uses an ensemble of state estimates to represent
the uncertainty in the estimated state. The ensemble Kalman filter
provides an approximation to the true state distribution.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchda.apply_KF">
<span class="sig-prename descclassname"><span class="pre">torchda.</span></span><span class="sig-name descname"><span class="pre">apply_KF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_obs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_GenericTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_GenericTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchda.apply_KF" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the Kalman Filter (constant P assumption).</p>
<p>This function applies the Kalman Filter algorithm to estimate
the state of a dynamic system given noisy measurements. It is executed
within a no-grad context, meaning that gradient computation is disabled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_obs</strong> (<em>_GenericTensor</em>) – A 1D array containing the observation times in increasing order.</p></li>
<li><p><strong>gaps</strong> (<em>_GenericTensor</em>) – A 1D array containing the number of time steps
between consecutive observations.</p></li>
<li><p><strong>M</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>, </em><em>_GenericTensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>] </em><em>|</em>) – Callable[…, torch.Tensor]
The state transition function (process model) that predicts the state
of the system given the previous state and the time range.
It should have the signature
M(x: torch.Tensor, time_range: torch.Tensor, *args) -&gt; torch.Tensor.
‘x’ is the state vector, ‘time_range’ is a 1D tensor of time steps
to predict the state forward, and ‘*args’ represents
any additional arguments required by the state transition function.</p></li>
<li><p><strong>H</strong> (<em>torch.Tensor</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em>) – The measurement matrix or a function that
computes the measurement matrix. If ‘H’ is a torch.Tensor,
it is a 2D tensor of shape (measurement_dim, state_dim),
where ‘measurement_dim’ is the dimension of measurement
and ‘state_dim’ is the dimension of the state vector.
This matrix maps the state space to the measurement space.
If ‘H’ is a Callable, it should have the signature
H(x: torch.Tensor) -&gt; torch.Tensor to compute the measurement,
and ‘H’ must be able to handle the input ‘x’ with shape
(state_dim,). The output of Callable ‘H’ must be a Tensor with shape
(measurement_dim,).
Note: Jacobian calculation on Neural Network ‘H’ might be incorrect
for the current Kalman Filter implementation.</p></li>
<li><p><strong>P0</strong> (<em>torch.Tensor</em>) – The initial covariance matrix of the state estimate. A 2D tensor of
shape (state_dim, state_dim).
It represents the uncertainty of the initial state estimate.</p></li>
<li><p><strong>R</strong> (<em>torch.Tensor</em>) – The measurement noise covariance matrix. A 2D tensor of shape
(measurement_dim, measurement_dim).
It models the uncertainty in the measurements.</p></li>
<li><p><strong>x0</strong> (<em>torch.Tensor</em>) – The initial state estimate. A 1D tensor of shape (state_dim).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – The observed measurements. A 2D tensor of shape
(number of observations, measurement_dim).
Each row represents a measurement at a specific time step.</p></li>
<li><p><strong>args</strong> (<em>tuple</em><em>, </em><em>optional</em>) – Additional arguments to pass to the state transition function ‘M’.</p></li>
<li><p><strong>start_time</strong> (<em>float</em><em>, </em><em>optional</em>) – The starting time of the filtering process. Default is 0.0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>x_estimates</strong> – Each row represents the estimated state vector
at a specific time step, including the initial state.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A 2D tensor of shape (num_steps + 1, state_dim).</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>TypeError</strong> – If ‘M’ is not a Callable or ‘H’ is not a torch.Tensor or Callable.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The function assumes that the input tensors are properly shaped
and valid for the Kalman Filter. Ensure that ‘x0’, ‘P0’, ‘R’,
and ‘y’ are appropriate for the dimensions of ‘M’ and ‘H’.</p></li>
<li><p>The function assumes that ‘time_obs’ contains time points
that are increasing, and ‘gaps’ specifies each number of time steps
between consecutive observations.</p></li>
<li><p>The implementation assumes a constant P assumption,
meaning the state estimate covariance matrix ‘P’ remains the same
throughout the filtering process. If a time-varying ‘P’ is
required, you need to modify the function accordingly.</p></li>
</ul>
</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">torchda</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>